{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0db91f23",
   "metadata": {},
   "source": [
    "# Issue2\n",
    "Die Funktion soll folgendes tun:\n",
    "Diese Funktion liest einen gesamten Modultext ein und macht daraus einen Dictionary. Möglicherweise ist dafür regex am\n",
    "Sinnvollsten.\n",
    "Diese Funktion kann dann innerhalb der Funktion aus issue#1 verwendet werden, und den dict erstellen, der dann im .json \n",
    "file gespeichert wird.\n",
    "\n",
    "Fehler: \n",
    "    IndexError: list index out of range\n",
    "    \n",
    "        Ich gehe davon aus, dass das Programm ein Problem hat, weil in der Spalte nichts drinnen steht\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce4f1dae",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 161\u001b[0m\n\u001b[0;32m    158\u001b[0m         json\u001b[38;5;241m.\u001b[39mdump(all_sections, f, ensure_ascii\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n\u001b[0;32m    160\u001b[0m \u001b[38;5;66;03m# Beispiel zur Verarbeitung einer Datei\u001b[39;00m\n\u001b[1;32m--> 161\u001b[0m process_file(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodulhandbuch.kurz.txt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[3], line 154\u001b[0m, in \u001b[0;36mprocess_file\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m    152\u001b[0m all_sections \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m section \u001b[38;5;129;01min\u001b[39;00m sections:\n\u001b[1;32m--> 154\u001b[0m     section_dict \u001b[38;5;241m=\u001b[39m parse_section_to_dict(section)\n\u001b[0;32m    155\u001b[0m     all_sections\u001b[38;5;241m.\u001b[39mappend(section_dict)\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput.json\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "Cell \u001b[1;32mIn[3], line 135\u001b[0m, in \u001b[0;36mparse_section_to_dict\u001b[1;34m(section)\u001b[0m\n\u001b[0;32m    131\u001b[0m     ueberblick_text \u001b[38;5;241m=\u001b[39m ueberblick_match\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[0;32m    132\u001b[0m     ueberblick_lines \u001b[38;5;241m=\u001b[39m ueberblick_text\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    133\u001b[0m     ueberblick_dict \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    134\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVeranstaltung\u001b[39m\u001b[38;5;124m\"\u001b[39m: ueberblick_lines[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(),\n\u001b[1;32m--> 135\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLV-Form\u001b[39m\u001b[38;5;124m\"\u001b[39m: ueberblick_lines[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(),\n\u001b[0;32m    136\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSWS\u001b[39m\u001b[38;5;124m\"\u001b[39m: ueberblick_lines[\u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(),\n\u001b[0;32m    137\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCP\u001b[39m\u001b[38;5;124m\"\u001b[39m: ueberblick_lines[\u001b[38;5;241m3\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(),\n\u001b[0;32m    138\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m: ueberblick_lines[\u001b[38;5;241m4\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(),\n\u001b[0;32m    139\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2\u001b[39m\u001b[38;5;124m\"\u001b[39m: ueberblick_lines[\u001b[38;5;241m5\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(),\n\u001b[0;32m    140\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m3\u001b[39m\u001b[38;5;124m\"\u001b[39m: ueberblick_lines[\u001b[38;5;241m6\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(),\n\u001b[0;32m    141\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m4\u001b[39m\u001b[38;5;124m\"\u001b[39m: ueberblick_lines[\u001b[38;5;241m7\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(),\n\u001b[0;32m    142\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m5\u001b[39m\u001b[38;5;124m\"\u001b[39m: ueberblick_lines[\u001b[38;5;241m8\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(),\n\u001b[0;32m    143\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m6\u001b[39m\u001b[38;5;124m\"\u001b[39m: ueberblick_lines[\u001b[38;5;241m9\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(),\n\u001b[0;32m    144\u001b[0m     }\n\u001b[0;32m    145\u001b[0m     section_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mÜbersicht\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m ueberblick_dict\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m section_dict\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "def split_text_file(filename):\n",
    "    encodings = ['utf-8', 'latin-1', 'iso-8859-1', 'cp1252']  # List of common codecs\n",
    "\n",
    "    content = None\n",
    "    for encoding in encodings:\n",
    "        try:\n",
    "            with open(filename, 'r', encoding=encoding) as file:\n",
    "                content = file.read()\n",
    "            break  # Break if reading was successful\n",
    "        except UnicodeDecodeError:\n",
    "            continue  # Try the next encoding\n",
    "        except FileNotFoundError:\n",
    "            raise FileNotFoundError(f\"The file {filename} was not found.\")\n",
    "    \n",
    "    if content is None:\n",
    "        raise ValueError(\"Failed to read the file with the given encodings.\")\n",
    "\n",
    "    # Ensure the delimiter 'B' is included at the beginning of each section\n",
    "    sections = content.split('\\n\\n\\n\\nB')\n",
    "    \n",
    "    # Add the 'B' back to the start of each section except the first one\n",
    "    sections = [sections[0]] + ['B' + sec for sec in sections[1:]]\n",
    "\n",
    "    # Remove leading and trailing whitespace from each section\n",
    "    sections = [sec.strip() for sec in sections]\n",
    "\n",
    "    return sections\n",
    "\n",
    "def generate_filename_from_first_line(section):\n",
    "    first_line = section.split('\\n', 1)[0].strip()\n",
    "    # Remove invalid filename characters\n",
    "    filename = \"\".join(x for x in first_line if (x.isalnum() or x in \"._- \")).strip()[:50]\n",
    "    return filename\n",
    "\n",
    "def parse_section_to_dict(section):\n",
    "    section_dict = {}\n",
    "    \n",
    "    # Extract Titel\n",
    "    titel_match = re.search(r'^(BP\\d+\\n.*?)(?=\\n\\n|$)', section, re.DOTALL)\n",
    "    if titel_match:\n",
    "        section_dict[\"Titel\"] = [line.strip() for line in titel_match.group(1).split('\\n')]\n",
    "\n",
    "    # Extract Inhalte\n",
    "    inhalte_match = re.search(r'Inhalte\\n\\n(.*?)(?=\\n\\n[A-Z])', section, re.DOTALL)\n",
    "    if inhalte_match:\n",
    "        section_dict[\"Inhalte\"] = inhalte_match.group(1).replace('\\n', ' ').strip()\n",
    "\n",
    "    # Extract Lernergebnisse / Kompetenzziele\n",
    "    lernergebnisse_match = re.search(r'Lernergebnisse / Kompetenzziele\\n\\n(.*?)(?=\\n\\n[A-Z])', section, re.DOTALL)\n",
    "    if lernergebnisse_match:\n",
    "        section_dict[\"Lernergebnisse / Kompetenzziele\"] = lernergebnisse_match.group(1).replace('\\n', ' ').strip()\n",
    "\n",
    "    # Extract Teilnahmevoraussetzungen\n",
    "    teilnahmevoraussetzungen_match = re.search(r'Teilnahmevoraussetzungen für Modul bzw. für einzelne Lehrveranstaltungen des Moduls\\n\\n(.*?)(?=\\n\\n[A-Z])', section, re.DOTALL)\n",
    "    if teilnahmevoraussetzungen_match:\n",
    "        section_dict[\"Teilnahmevoraussetzungen für Modul bzw. für einzelne Lehrveranstaltungen des Moduls\"] = teilnahmevoraussetzungen_match.group(1).replace('\\n', ' ').strip()\n",
    "\n",
    "    # Extract Empfohlene Voraussetzungen\n",
    "    empfohlene_voraussetzungen_match = re.search(r'Empfohlene Voraussetzungen\\n\\n(.*?)(?=\\n\\n[A-Z])', section, re.DOTALL)\n",
    "    if empfohlene_voraussetzungen_match:\n",
    "        section_dict[\"Empfohlene Voraussetzungen\"] = empfohlene_voraussetzungen_match.group(1).replace('\\n', ' ').strip()\n",
    "\n",
    "    # Extract Organisatorische Hinweise\n",
    "    organisatorische_hinweise_match = re.search(r'Organisatorische Hinweise\\n\\n(.*?)(?=\\n\\n[A-Z])', section, re.DOTALL)\n",
    "    if organisatorische_hinweise_match:\n",
    "        section_dict[\"Organisatorische Hinweise\"] = organisatorische_hinweise_match.group(1).replace('\\n', ' ').strip()\n",
    "\n",
    "    # Extract Zuordnung des Moduls\n",
    "    zuordnung_moduls_match = re.search(r'Zuordnung des Moduls \\(Studiengang / Fachbereich\\)\\n(.*?)(?=\\n\\n[A-Z])', section, re.DOTALL)\n",
    "    if zuordnung_moduls_match:\n",
    "        section_dict[\"Zuordnung des Moduls (Studiengang / Fachbereich)\"] = zuordnung_moduls_match.group(1).replace('\\n', ' ').strip()\n",
    "\n",
    "    # Extract Verwendbarkeit des Moduls\n",
    "    verwendbarkeit_moduls_match = re.search(r'Verwendbarkeit des Moduls \\n(.*?)(?=\\n\\n[A-Z])', section, re.DOTALL)\n",
    "    if verwendbarkeit_moduls_match:\n",
    "        section_dict[\"Verwendbarkeit des Moduls für andere Studiengänge\"] = verwendbarkeit_moduls_match.group(1).replace('\\n', ' ').strip()\n",
    "\n",
    "    # Extract Häufigkeit des Angebots\n",
    "    haeufigkeit_angebots_match = re.search(r'Häufigkeit des Angebots\\n(.*?)(?=\\n\\n[A-Z])', section, re.DOTALL)\n",
    "    if haeufigkeit_angebots_match:\n",
    "        section_dict[\"Häufigkeit des Angebots\"] = haeufigkeit_angebots_match.group(1).replace('\\n', ' ').strip()\n",
    "\n",
    "    # Extract Dauer des Moduls\n",
    "    dauer_moduls_match = re.search(r'Dauer des Moduls\\n(.*?)(?=\\n\\n[A-Z])', section, re.DOTALL)\n",
    "    if dauer_moduls_match:\n",
    "        section_dict[\"Dauer des Moduls\"] = dauer_moduls_match.group(1).replace('\\n', ' ').strip()\n",
    "\n",
    "    # Extract Modulbeauftragte / Modulbeauftragter\n",
    "    modulbeauftragte_match = re.search(r'Modulbeauftragte / Modulbeauftragter\\n(.*?)(?=\\n\\n[A-Z])', section, re.DOTALL)\n",
    "    if modulbeauftragte_match:\n",
    "        section_dict[\"Modulbeauftragte / Modulbeauftragter\"] = modulbeauftragte_match.group(1).replace('\\n', ' ').strip()\n",
    "\n",
    "    # Extract Studiennachweise/ ggf. als Prüfungsvorleistungen\n",
    "    studiennachweise_match = re.search(r'Studiennachweise/ ggf. als Prüfungsvorleistungen\\n\\n(.*?)(?=\\n\\n[A-Z])', section, re.DOTALL)\n",
    "    if studiennachweise_match:\n",
    "        studiennachweise_text = studiennachweise_match.group(1).replace('\\n', ' ').strip()\n",
    "        studiennachweise_parts = studiennachweise_text.split('Leistungsnachweise')\n",
    "        if len(studiennachweise_parts) == 2:\n",
    "            section_dict[\"Studiennachweise/ ggf. als Prüfungsvorleistungen\"] = {\n",
    "                \"Teilnahmenachweise\": studiennachweise_parts[0].strip() if studiennachweise_parts[0].strip() else \"keine\",\n",
    "                \"Leistungsnachweise\": studiennachweise_parts[1].strip()\n",
    "            }\n",
    "\n",
    "    # Extract Lehr- / Lernformen\n",
    "    lehr_lernformen_match = re.search(r'Lehr- / Lernformen\\n(.*?)(?=\\n\\n[A-Z])', section, re.DOTALL)\n",
    "    if lehr_lernformen_match:\n",
    "        section_dict[\"Lehr- / Lernformen\"] = lehr_lernformen_match.group(1).replace('\\n', ' ').strip()\n",
    "\n",
    "    # Extract Unterrichts- / Prüfungssprache\n",
    "    unterricht_pruefungssprache_match = re.search(r'Unterrichts- / Prüfungssprache\\n(.*?)(?=\\n\\n[A-Z])', section, re.DOTALL)\n",
    "    if unterricht_pruefungssprache_match:\n",
    "        section_dict[\"Unterrichts- / Prüfungssprache\"] = unterricht_pruefungssprache_match.group(1).replace('\\n', ' ').strip()\n",
    "\n",
    "    # Extract Modulprüfung\n",
    "    modulpruefung_match = re.search(r'Modulprüfung\\n\\n(.*?)(?=\\n\\n[A-Z])', section, re.DOTALL)\n",
    "    if modulpruefung_match:\n",
    "        modulpruefung_text = modulpruefung_match.group(1).replace('\\n', ' ').strip()\n",
    "        modulpruefung_parts = modulpruefung_text.split('kumulative Modulprüfung bestehend aus:')\n",
    "        if len(modulpruefung_parts) == 2:\n",
    "            section_dict[\"Modulprüfung\"] = {\n",
    "                \"Modulabschlussprüfung bestehend aus:\": modulpruefung_parts[0].strip(),\n",
    "                \"kumulative Modulprüfung bestehend aus:\": modulpruefung_parts[1].strip()\n",
    "            }\n",
    "\n",
    "    # Extract Übersicht\n",
    "    ueberblick_match = re.search(r'LV-Form\\nSWS\\nCP\\nSemester\\n(.*?)(?=\\n\\n[A-Z])', section, re.DOTALL)\n",
    "    if ueberblick_match:\n",
    "        ueberblick_text = ueberblick_match.group(1).replace('\\n', ' ').strip()\n",
    "        ueberblick_lines = ueberblick_text.split('\\n')\n",
    "        ueberblick_dict = {\n",
    "            \"Veranstaltung\": ueberblick_lines[0].split(),\n",
    "            \"LV-Form\": ueberblick_lines[1].split(),\n",
    "            \"SWS\": ueberblick_lines[2].split(),\n",
    "            \"CP\": ueberblick_lines[3].split(),\n",
    "            \"1\": ueberblick_lines[4].split(),\n",
    "            \"2\": ueberblick_lines[5].split(),\n",
    "            \"3\": ueberblick_lines[6].split(),\n",
    "            \"4\": ueberblick_lines[7].split(),\n",
    "            \"5\": ueberblick_lines[8].split(),\n",
    "            \"6\": ueberblick_lines[9].split(),\n",
    "        }\n",
    "        section_dict[\"Übersicht\"] = ueberblick_dict\n",
    "\n",
    "    return section_dict\n",
    "\n",
    "def process_file(filename):\n",
    "    sections = split_text_file(filename)\n",
    "\n",
    "    all_sections = []\n",
    "    for section in sections:\n",
    "        section_dict = parse_section_to_dict(section)\n",
    "        all_sections.append(section_dict)\n",
    "    \n",
    "    with open('output.json', 'w', encoding='utf-8') as f:\n",
    "        json.dump(all_sections, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "# Beispiel zur Verarbeitung einer Datei\n",
    "process_file('modulhandbuch.kurz.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4fd35d6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
